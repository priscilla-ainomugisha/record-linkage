{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "dataset1 = pd.read_csv('synthetic_facility_v3.csv')\n",
    "dataset2 = pd.read_csv('synthetic_hdss_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column in he hdss dataset cause it is null throughout\n",
    "dataset2 = dataset2.drop(columns=['nationalid'], errors='ignore')\n",
    "\n",
    "# The dates are actually fine, i realised they are different people and they all have the same format\n",
    "# Maybe we can work on first trying to match the patient names in the different databases\n",
    "\n",
    "#The petnames are okay cause they belong to different people\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching patient names saved to matching_patient_names.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming the patient name columns are named 'patient_name' in both datasets\n",
    "\n",
    "# Convert patient names to lowercase for case-insensitive matching\n",
    "dataset1['firstname'] = dataset1['firstname'].str.lower()\n",
    "dataset2['firstname'] = dataset2['firstname'].str.lower()\n",
    "\n",
    "# Find matching patient names\n",
    "matching_names = pd.merge(dataset1, dataset2, on='firstname', how='inner')\n",
    "\n",
    "# Save the matching patient names to a new CSV file\n",
    "matching_names.to_csv('matching_patient_names.csv', index=False)\n",
    "\n",
    "print(\"Matching patient names saved to matching_patient_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching full names saved to matching_full_names.csv\n"
     ]
    }
   ],
   "source": [
    "#Matching both firstname and last name\n",
    "\n",
    "# Concatenate last and first names into a single column for both datasets\n",
    "dataset1['full_name'] = dataset1['lastname'] + ' ' + dataset1['firstname']\n",
    "dataset2['full_name'] = dataset2['lastname'] + ' ' + dataset2['firstname']\n",
    "\n",
    "\n",
    "# Convert full names to lowercase for case-insensitive matching\n",
    "dataset1['full_name'] = dataset1['full_name'].str.lower()\n",
    "dataset2['full_name'] = dataset2['full_name'].str.lower()\n",
    "\n",
    "\n",
    "# Find matching full names\n",
    "matching_names = pd.merge(dataset1, dataset2, on='full_name', how='inner')\n",
    "\n",
    "# Save the matching full names to a new CSV file\n",
    "matching_names.to_csv('matching_full_names2.csv', index=False)\n",
    "\n",
    "print(\"Matching full names saved to matching_full_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splink'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msplink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splink_datasets\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dataset1\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'splink'"
     ]
    }
   ],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "import altair as alt\n",
    "\n",
    "dataset1.head(5)\n",
    "dataset2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the linker, passing in the input dataset(s)\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "linker = DuckDBLinker(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the linker, passing in the input dataset(s)\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "linker = DuckDBLinker(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.missingness_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.profile_columns(top_n=10, bottom_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "settings = {\"link_type\": \"dedupe_only\"}\n",
    "linker = DuckDBLinker(df, settings)\n",
    "\n",
    "blocking_rule_1 = block_on([\"substr(first_name, 1,1)\", \"surname\"])\n",
    "count = linker.count_num_comparisons_from_blocking_rule(blocking_rule_1)\n",
    "print(f\"Number of comparisons generated by '{blocking_rule_1.blocking_rule_sql}': {count:,.0f}\")\n",
    "\n",
    "blocking_rule_2 = block_on(\"surname\")\n",
    "count = linker.count_num_comparisons_from_blocking_rule(blocking_rule_2)\n",
    "print(f\"Number of comparisons generated by '{blocking_rule_2.blocking_rule_sql}': {count:,.0f}\")\n",
    "\n",
    "blocking_rule_3 = block_on(\"email\")\n",
    "count = linker.count_num_comparisons_from_blocking_rule(blocking_rule_3)\n",
    "print(f\"Number of comparisons generated by '{blocking_rule_3.blocking_rule_sql}': {count:,.0f}\")\n",
    "\n",
    "blocking_rule_4 = block_on([\"city\", \"first_name\"])\n",
    "count = linker.count_num_comparisons_from_blocking_rule(blocking_rule_4)\n",
    "print(f\"Number of comparisons generated by '{blocking_rule_4.blocking_rule_sql}': {count:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n",
    "        cl.exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        ctl.email_comparison(\"email\", include_username_fuzzy_level=False),\n",
    "    ],\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on(\"first_name\"),\n",
    "        block_on(\"surname\"),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) &lt;= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) &lt;= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) &lt;= 2\",\n",
    "    \"l.email = r.email\"\n",
    "]\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_blocking_rule = block_on([\"first_name\", \"surname\"])\n",
    "training_session_fname_sname = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import fix\n",
    "\n",
    "\n",
    "training_blocking_rule = block_on(\"dob\")\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = linker.save_model_to_json(\"../demo_settings/saved_model_from_demo.json\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
